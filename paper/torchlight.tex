\documentclass[acmsmall, nonacm]{acmart}

% %%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% end of the preamble, start of the body of the document source.
\begin{document}

\title{Torchlight: Diffusion-based Network Trace Generation from the DARPA Searchlight Dataset}

\author{Ray Zhao}
\affiliation{%
 \institution{University of Southern California}
 \city{Los Angeles}
 \state{California}
 \country{}}
\email{rdzhao@usc.edu}

\author{Alefiya Hussain}
\affiliation{%
  \institution{USC/ISI}
  \city{Los Angeles}
  \country{}}
\email{hussain@isi.edu}

\renewcommand{\shortauthors}{Zhao, Hussain}

\begin{abstract}
  At present, there is a severe lack of both comprehensive and realistic labeled datasets
  for machine learning applications in the networking domain. Predominantly, prior generative
  work has focused on lower-dimensional representations that rely on aggregating flow 
  characteristics and lack the fine-grain of raw network traces. This results in suboptimal
  performance in machine learning contexts and limited applications outside of those 
  contexts. This has induced a push for new generative techniques to provide 
  synthetic data for usage both on its own and layered in with real data as augmentation.
  In this paper, we present Torchlight, a diffusion-based
  generation framework built atop and extending techniques first introduced in 
  \textit{NetDiffusion} \cite{Jiang2024} using DARPA Searchlight \cite{Ardi2022} data to generate synthetic network traces
  for video streaming applications. We demonstrate the efficacy of Torchlight in generating
  synthetic network traces that reasonably resemble real-world data and perform notably well
  in classification tasks. 
\end{abstract}

\maketitle

\section{Introduction}
There's a large need and general scarcity of labeled network datasets,
as high-quality data is often expensive and frought with privacy concerns,
and the datasets that do exist are often left rarely update over time.
Synthetic data generation techniques aim to solve this problem, but prior
GAN based methodologies have been limited in their ability to generate
raw, high-dimensional traces and often rely on aggregating flow characteristics,
which results in data that lacks statistical fidelity to real data and performs
much more poorly in machine learning tasks. The highly specific formatting of
these types of condensed traces also renders them generally incompatible with
traditional tools like Wireshark and tcpdump.

In recent years, the advent of diffusion models have solved many of the
problems that plague older GAN frameworks, being able to capture much
more complex patterns and relationships. They also usually offer much more
stability in the training process, in which GANs are notably finnicky.
Additionally, their now near-hegemony in the image generation space has
enabled a wide base of development support in the diffusion community 
and has also made available many "plug and play"
means of constraining generation to appropriate enough scopes for specific generation
tasks like the one at hand.

As it pertains to Torchlight, we build on the NetDiffusion framework pioneered
by Jiang et al. \cite{Jiang2024} to generate synthetic network traces for video
streaming applications, using the DARPA Searchlight dataset \cite{Ardi2022} as
our base. Our contributions are as follows:

\begin{enumerate}
  \item \textbf{Successful application of NetDiffusion techniques on the Searchlight Dataset}:
  Using the pre-processing and post-processing code provided by Jiang et al., we were able to
  successfully generate synthetic traces that performed capably on its own as training
  data for classification tasks as well as when used in conjunction with real data 
  as augmentation.
  \item \textbf{Streamlining the generation process}: While the original NetDiffusion codebase
  used exterrnally-built WebUIs for LoRA fine-tuning as well as the Controlnet, 
  these two major components were integrated into the codebase such that the 
  entire process can be run from a single script.
\end{enumerate}

\section{Motivation \& Related Work}
Publicly available network data is crucial in this field for enabling continued
researhc and development of new networking technologies and techniques. While useful for
more traditional networking analysis tasks, machine learning applications have been driving
much of the development in use-cases like anomaly detection and traffic classification and 
in particular have largely relied on these datasets.

\subsection{Cost and Scarcity}
Notable datasets like DARPA Searchlight and CAIDA have been essential 
in the development of new networking technologies, but expensive and complex
to develop and then maintain. Entities with the means to develop these datasets
often have little incentive to release them to the public, as they are often
highly proprietary and run into ethics concerns. Even when they are released, 
they are often left to stagnate and lose relevance over time, as the networking
landscape is highly dynamic.

\subsection{Data Augmentation}
In the absence of high-quality labeled data, data augmentation has been a popular
technique, especially in computer vision, to extend the utility of exisiting
and the models with which they are used. Synthetic data generation has been
successful across domains, with GANs being dominant in the image generation space
and autoencoders being popular in creating synthetic text data. 

The most notable application of synthetic data generation in networking has been
in the realm of flow-based data, where the data is aggregated into flows and then
used to generate synthetic data. This has been successful in some applications, 
most notably NetShare \cite{NetShare}, which produces NetFlow-like aggregates 
on network traffic. The limited dimensionality of these aggregates, however, 
means much coaser-grained pattern capture and limited utility outside of 
pure model training.

The original authors of NetDiffusion \cite{Jiang2024} have shown that
NetFlow data performs poorly in classification tasks in comparison to raw 
traffic data, and as such have been motivated to develop a new framework
that can generate raw traces.

\section{Methods}
Here we outline the framework used in Torchlight to generate synthetic network traces,
which is built atop NetDiffusion \cite{Jiang2024} and updates and streamlines it.
Our approach is segmented into five primary moving parts:

\begin{enumerate}
  \item Conversion of raw network traces in \verb|.pcap| format into images
  \item Fine-tuning a pretrained diffusion model with LoRA on the labelled images
  \item ControlNet constrained generation of synthetic traces
  \item Color correction and network compliance post-processing
  \item Conversion of generated and processed images back into \verb|.pcap| format
\end{enumerate}

\subsection{Trace to Image Conversion}
This work is anchored on the core concept of encapsulating raw network data
into a dense image format. Pixels in images inherently form high-dimensional 
patterns and structures with long-range, highly non-linear dependencies.
While tabular formats typically engender points as indepedent entities, images 
much more adeptly preserve temporal and spatial relationships between network
flows that traditional tabular formats do not. Development in the image space has always been
rapid and deep-learning and subsequent generative techniques have been refined 
over time to capture these complex relationships. As importantly, this format
allows us to exploit the maturity and computational throughput
of image-based deep learning. Diffusion models are
the newest and most powerful of these techniques, and have been shown to be of
great utility in the image generation space. We will delve into more detail on
this in the next section.

Our image representation is expressed with the nPrint \cite{nPrint} format, which
standardizes the irregular and high-dimensional network patterns of raw 
traces into a consistent bit-mapped format, where the presence or absence of a bit
in the packet header is denoted 1 or 0 respectively, and a missing header bit is
represented as -1. The payload content is not encoded since it's often encrypted, 
but size of payloads can be inferred from other encoded header fields. 
With this, a sequence of pcaps is converted into a matrix which can be formatted
as an image. A set bit (1), an unset bit (0), and a vacant bit (-1) are 
represented by green, red, and blue respectively. 
Due to the limitations in generative modelsâ€™ capability to handle very high
dimensional data and standard image processing practice, we group packets in 
groups of 1024, resulting in a $1088 \times 1024$ image with each row of pixels
representing a packet in the network traffic flow as shown in Figure 2. 

\subsection{Model Fine-Tuning}
\subsubsection{Why diffusion models?}
Diffusion models fundamentally operate on the principle of iteratively updating
a set of latent variables to approximate a true data distribution, taking
a randomly initialized amount of noise and progressively refining it to
generate an image. A differential equation is used to control the transformation
of an initial noise vector $\mathbf{z}$ into a data point $\mathbf{x}$ over a 
series of time steps. This process is modeled by estimating the gradient of the
log-likelihood of the data with respect to the noise vector, and then using this
gradient to update the noise vector. Diffusion models typically operate in the
context of "text-to-image" synthesis, where a text prompt guides the 
generation of an image by conditioning the noise vector on the text. This
conditioning steers the data distribution from a general uniform prior distribution
to a more specific one fitted to the text prompt.

This process lends a number of advantages to diffusion, as opposed to other
generative techniques. Diffusion models have been shown to be adept at capturing
highly complex and intricate relationships and generating high-resolution
images. The text conditioning also allows for a high degree of control over
the generated images, as the text can be used to guide the generation process
in a way that is not possible with other generative models. Lastly,
diffusion models are highly stable and easy to train, as they do not require
the adversarial training that GANs do, and are much less prone to mode collapse.
Their stable gradient dynamics and ability to be seeded in training
ensures not just consistent but reproducible training results.

\subsubsection{Fine-tuning with LoRA.} Training a diffusion model from scratch
is highly computationally intensive and expensive, especially considering that
existing models are often trained on billions of images. While good for general
applications, base models like Stable Diffusion are too broad for our purposes. 
While a text prompt like "pixelated network data: dash, 1080" is what we end up 
using in our end-stage model, the base model would produce something 
like a pixelated image of a dash, which is not useful for our purposes. Low-Rank
Adaptation (LoRA) is a technique that allows us to fine-tune a pre-trained model
on a smaller dataset, which is much more computationally feasible. LoRA works by
attaching a low-rank matrix to the model's parameters and then training just 
the low-rank matrix on a new dataset. This allows us to adapt the stylistic and
color characteristics of the model to our specific dataset without having to
retrain the entire model.

In the fine-tuning process, we attach to every image a caption that corresponds
to the various characteristics of the image. For example, the image for
a network flow using the Wireguard VPN streaming 1080p video using DASH over
HTTP3 would be captioned "pixelated network data: wireguardptp, dash, 1080 hhtp3".
Hundreds of such image-caption pairs are then used to fine-tune the model over
the course of thousands of epochs to adapt the model to the specific 
color and stylistic characteristics of the images used to fine-tune it. 
The choice of caption is crucial and achieves two main objectives:
it gives the model a specific vocabulary that reduces ambiguity and minimizes
interference from the original word embeddings of the base model.

\subsection{Constrained Generation}
Even though fine-tuning can result in very high-quality output, it can
be very abstract and deviate greatly from the stricter bounds of network 
traffic data. To constrain the output, we can employ a ControlNet, which
is a separate neural network that sits atop the diffusion model and
modifies the output to be rigidly within the bounds defined by the 
ControlNet. Generally, a ControlNet is trained on a specific type of
spatial constraint, like poses, depth mapping, masks, or in our case,
canny edge detection. In the case of canny edge detection, the ControlNet 
takes as input a text prompt and the canny edges extracted from a sample image
to use as "guardrails" to guide the diffusion model in generating the final image.
ControlNet enables us to generate images that are not just high-quality,
but also highly compliant with the structure of network traffic.

insert controlnet figure here

\subsection{Post-Processing}
While the constrained diffusion model generates high-fidelity images
that greatly \textit{resemble} network traffic, use outside of ML tasks
require that the flows these images represent comply with network standards 
and the multitudes of inter and intra packet dependices that enable use 
in traditional networking applications. While ControlNet can do a lot to
ensure resemblance, it cannot guarantee compliance. To this end, 
we must apply a series
of post-processing steps to the generated images to ensure that they are
compliant with network standards. Broadly, these rules can be put into two
categories:
\begin{enumerate}
  \item \textbf{Inter-Packet}: Rules that govern the sequencing between
  header fields between packets in a flow, like the SYN / SYN-ACK handshake
  that initiates a TCP connection, the incorrect alignment of which can
  cause the connection to fail.
  \item \textbf{Intra-Packet}: Rules that organize the structure of individual
  packets, like the ordering of header fields within a packet and checksums
  that ensure the integrity of the packet.
\end{enumerate}

Most of the work of creating a systematic approach that comprehensively 
identifes and corrects these errors has been done by original 
NetDiffusion authors, and we have largely built on their work in this
area. The post-processing steps are fully automated and accomplished
by traversing two intra-packet and inter-packet dependency trees built
with domain knowledge. A notable challenge the authors faced was
time-stamp assignment for packets, which was resolved by sampling 
original timestamps from real data to produce similar timestamp distributions
in the synthetic data. This post-processing ensures that the generated
traffic can be smoothly converted into raw network formats and utilized
in non-ML contexts.

\subsection{Image to Trace Conversion}
The final step in the process is to convert the generated images back
into network traces and is relatively straightfoward.
This is done by reversing the process used to convert
the original traces into images. The generated images are first converted
into nPrint format, and then the nPrint format is converted back into
a sequence of pcaps. The post-processing steps ensure that the generated
pcaps are compliant with network standards and can be used in traditional
networking applications.

\section{Evaluation}
The assessment of this framework is done primarily in gauging its performance
in machine learning classification tasks. While the original NetDiffusion paper
goes into great detail about the performance of the generated in outside
applications, we focus on the classification task as it is the most common
use-case for synthetic data in networking.

\subsection{Dataset Overview \& Generation}
The data used is the DARPA Searchlight dataset \cite{Ardi2022}, which is a large
collection of network traces from a variety of sources and applications. Searchlight
was collected over a period of 6 months and contains a wide variety of traffic types,
including video streaming, web browsing, and file transfers all coordinated on a 
complex testbed that includes a variety of network devices and topologies, making it
highly representative of real-world network traffic. We focus on video streaming
traffic in our work.

\subsection{Classification Results}

\begin{acks}
To Alefiya, for the continual guidance and enthusiam all throughout
the project
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%%
%% If your work has an appendix, this is the place to put it.
\appendix
\end{document}
\endinput